<!-- HTML header for doxygen 1.8.4-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="keywords" content="madlib,postgres,greenplum,machine learning,data mining,deep learning,ensemble methods,data science,market basket analysis,affinity analysis,pca,lda,regression,elastic net,huber white,proportional hazards,k-means,latent dirichlet allocation,bayes,support vector machines,svm"/>
<title>MADlib: Multinomial Logistic Regression</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<!-- hack in the navigation tree -->
<script type="text/javascript" src="eigen_navtree_hacks.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="madlib_extra.css" rel="stylesheet" type="text/css"/>
<!-- google analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45382226-1', 'madlib.apache.org');
  ga('send', 'pageview');
</script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><a href="http://madlib.apache.org"><img alt="Logo" src="madlib.png" height="50" style="padding-left:0.5em;" border="0"/ ></a></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   <span id="projectnumber">1.15.1</span>
   </div>
   <div id="projectbrief">User Documentation for Apache MADlib</div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('group__grp__mlogreg.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Multinomial Logistic Regression<div class="ingroups"><a class="el" href="group__grp__deprecated.html">Deprecated Modules</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<dl class="section warning"><dt>Warning</dt><dd><em> This is an old implementation of multinomial logistic regression. Replacement of this function is available as the Multinomial regression module <a class="el" href="group__grp__multinom.html">Multinomial Regression</a></em></dd></dl>
<div class="toc"><b>Contents</b> <ul>
<li class="level1">
<a href="#train">Training Function</a> </li>
<li class="level1">
<a href="#predict">Prediction Function</a> </li>
<li class="level1">
<a href="#examples">Examples</a> </li>
<li class="level1">
<a href="#background">Technical Background</a> </li>
<li class="level1">
<a href="#literature">Literature</a> </li>
<li class="level1">
<a href="#related">Related Topics</a> </li>
</ul>
</div><p>Multinomial logistic regression is a widely used regression analysis tool that models the outcomes of categorical dependent random variables. The model assumes that the conditional mean of the dependent categorical variables is the logistic function of an affine combination of independent variables. Multinomial logistic regression finds the vector of coefficients that maximizes the likelihood of the observations.</p>
<p><a class="anchor" id="train"></a></p><dl class="section user"><dt>Training Function</dt><dd>The multinomial logistic regression training function has the following syntax: <pre class="syntax">
mlogregr_train(source_table,
               output_table,
               dependent_varname,
               independent_varname,
               ref_category,
               optimizer_params
              )
</pre> <b>Arguments</b> <dl class="arglist">
<dt>source_table </dt>
<dd><p class="startdd">TEXT. The name of the table containing the input data.</p>
<p></p>
<p class="enddd"></p>
</dd>
<dt>output_table </dt>
<dd><p class="startdd">TEXT. The name of the generated table containing the output model. The output table produced by the multinomial logistic regression training function contains the following columns: </p><table class="output">
<tr>
<th>category </th><td>INTEGER. The category. Categories are encoded as integers with values from {0, 1, 2,..., <em>numCategories</em> &ndash; 1}  </td></tr>
<tr>
<th>ref_category </th><td>INTEGER. The reference category. Categories are encoded as integers with values from {0, 1, 2,..., <em>numCategories</em> &ndash; 1}  </td></tr>
<tr>
<th>coef </th><td>FLOAT8[]. An array of coefficients, \( \boldsymbol c \).   </td></tr>
<tr>
<th>log_likelihood </th><td>FLOAT8. The log-likelihood, \( l(\boldsymbol c) \).  </td></tr>
<tr>
<th>std_err </th><td>FLOAT8[]. An array of the standard errors.  </td></tr>
<tr>
<th>z_stats </th><td>FLOAT8[]. An array of the Wald z-statistics.  </td></tr>
<tr>
<th>p_values </th><td>FLOAT8[]. An array of the Wald p-values.  </td></tr>
<tr>
<th>odds_ratios </th><td>FLOAT8[]. An array of the odds ratios.  </td></tr>
<tr>
<th>condition_no </th><td>FLOAT8. The condition number of the matrix, computed using the coefficients of the iteration immediately preceding convergence.  </td></tr>
<tr>
<th>num_iterations </th><td>INTEGER. The number of iterations executed before the algorithm completed.  </td></tr>
</table>
<p>A summary table named &lt;out_table&gt;_summary is also created at the same time, and it contains the following columns:</p>
<table class="output">
<tr>
<th>source_table </th><td>The data source table name.  </td></tr>
<tr>
<th>out_table </th><td>The output table name.  </td></tr>
<tr>
<th>dependent_varname </th><td>The dependent variable.  </td></tr>
<tr>
<th>independent_varname </th><td>The independent variables.  </td></tr>
<tr>
<th>optimizer_params </th><td>The optimizer parameters. It is a copy of the optimizer_params in the training function's arguments.  </td></tr>
<tr>
<th>ref_category </th><td>An integer, the value of reference category used.  </td></tr>
<tr>
<th>num_rows_processed </th><td>INTEGER. The number of rows actually processed, which is equal to the total number of rows in the source table minus the number of skipped rows.  </td></tr>
<tr>
<th>num_missing_rows_skipped </th><td>INTEGER. The number of rows skipped during the training. A row will be skipped if the ind_col is NULL or contains NULL values.  </td></tr>
</table>
<p class="enddd"></p>
</dd>
<dt>dependent_varname </dt>
<dd><p class="startdd">TEXT. The name of the column containing the dependent variable.</p>
<p class="enddd"></p>
</dd>
<dt>independent_varname </dt>
<dd><p class="startdd">TEXT. Expression list to evaluate for the independent variables. An intercept variable is not assumed. The number of independent variables cannot exceed 65535.</p>
<p class="enddd"></p>
</dd>
<dt>ref_category (optional) </dt>
<dd><p class="startdd">INTEGER, default: 0. The reference category ranges from [0, <em>numCategories</em> &ndash; 1].</p>
<p class="enddd"></p>
</dd>
<dt>optimizer_params (optional) </dt>
<dd>VARCHAR, default: NULL, which uses the default values of optimizer parameters. It should be a string that contains pairs of 'key=value' separated by commas. Supported parameters with their default values: max_iter=20, optimizer='irls', precision=1e-4. Currently, only 'irls' and 'newton' are allowed for 'optimizer'.  </dd>
</dl>
</dd></dl>
<dl class="section note"><dt>Note</dt><dd>Table names can be optionally schema qualified and table and column names should follow the same case-sensitivity and quoting rules as in the database.</dd></dl>
<p><a class="anchor" id="predict"></a></p><dl class="section user"><dt>Prediction Function</dt><dd>The prediction function is provided to estimate the conditional mean given a new predictor. It has the following syntax: <pre class="syntax">
mlogregr_predict(
    model_table,
    new_data_table,
    id_col_name,
    output_table,
    type)
</pre></dd></dl>
<p><b>Arguments</b> </p><dl class="arglist">
<dt>model_table </dt>
<dd><p class="startdd">TEXT. Name of the table containing the multilogistic model. This should be the output table returned from <em>mlogregr_train</em>.</p>
<p class="enddd"></p>
</dd>
<dt>new_data_table </dt>
<dd><p class="startdd">TEXT. Name of the table containing prediction data. This table is expected to contain the same features that were used during training. The table should also contain <em>id_col_name</em> used for identifying each row.</p>
<p class="enddd"></p>
</dd>
<dt>id_col_name </dt>
<dd><p class="startdd">TEXT. Name of the column containing id information in the source data. This is a mandatory argument and is used for correlating prediction table rows with the source. The values of this column are expected to be unique for each tuple. </p>
<p class="enddd"></p>
</dd>
<dt>output_table </dt>
<dd><p class="startdd">TEXT. Name of the table to output prediction results to. If this table already exists then an error is returned. This output table contains the <em>id_col_name</em> column giving the 'id' for each prediction.</p>
<p>If <em>type</em> = 'response', then the table has a single additional column with the prediction value of the response. The type of this column depends on the type of the response variable used during training.</p>
<p>If <em>type</em> = 'prob', then the table has multiple additional columns, one for each possible category. The columns are labeled as 'estimated_prob_<em>category_value</em>', where <em>category_value</em> represents the values of categories (0 to K-1).</p>
<p class="enddd"></p>
</dd>
<dt>type </dt>
<dd><p class="startdd">TEXT, optional, default: 'response'.</p>
<p>When <em>type</em> = 'prob', the probabilities of each category (including the reference category) is given.</p>
<p class="enddd">When <em>type</em> = 'response', a single output is provided which represents the prediction category for each tuple. This represents the category with the highest probability.  </p>
</dd>
</dl>
<p><a class="anchor" id="examples"></a></p><dl class="section user"><dt>Examples</dt><dd></dd></dl>
<ol type="1">
<li>Create the training data table. <pre class="example">
DROP TABLE IF EXISTS test3;
CREATE TABLE test3 (
    feat1 INTEGER,
    feat2 INTEGER,
    cat INTEGER
);
INSERT INTO test3(feat1, feat2, cat) VALUES
(1,35,1),
(2,33,0),
(3,39,1),
(1,37,1),
(2,31,1),
(3,36,0),
(2,36,1),
(2,31,1),
(2,41,1),
(2,37,1),
(1,44,1),
(3,33,2),
(1,31,1),
(2,44,1),
(1,35,1),
(1,44,0),
(1,46,0),
(2,46,1),
(2,46,2),
(3,49,1),
(2,39,0),
(2,44,1),
(1,47,1),
(1,44,1),
(1,37,2),
(3,38,2),
(1,49,0),
(2,44,0),
(3,61,2),
(1,65,2),
(3,67,1),
(3,65,2),
(1,65,2),
(2,67,2),
(1,65,2),
(1,62,2),
(3,52,2),
(3,63,2),
(2,59,2),
(3,65,2),
(2,59,0),
(3,67,2),
(3,67,2),
(3,60,2),
(3,67,2),
(3,62,2),
(2,54,2),
(3,65,2),
(3,62,2),
(2,59,2),
(3,60,2),
(3,63,2),
(3,65,2),
(2,63,1),
(2,67,2),
(2,65,2),
(2,62,2);
</pre></li>
<li>Run the multilogistic regression function. <pre class="example">
DROP TABLE IF EXISTS test3_output;
DROP TABLE IF EXISTS test3_output_summary;
SELECT madlib.mlogregr_train('test3',
                             'test3_output',
                             'cat',
                             'ARRAY[1, feat1, feat2]',
                             0,
                             'max_iter=20, optimizer=irls, precision=0.0001'
                             );
</pre></li>
<li>View the result: <pre class="example">
-- Set extended display on for easier reading of output
\x on
SELECT * FROM test3_output;
</pre> Results: <pre class="result">
-[ RECORD 1 ]--+------------------------------------------------------------
category       | 1
ref_category   | 0
coef           | {1.45474045211601,0.0849956182104023,-0.0172383499601956}
loglikelihood  | -39.14759930999
std_err        | {2.13085072854143,0.585021661344715,0.0431487356292144}
z_stats        | {0.682704063982831,0.145286275409074,-0.39950996729842}
p_values       | {0.494793861210936,0.884484850387893,0.689517480964129}
odd_ratios     | {4.28337158128448,1.08871229617973,0.982909380301134}
condition_no   | 280069.034217586
num_iterations | 5
-[ RECORD 2 ]--+------------------------------------------------------------
category       | 2
ref_category   | 0
coef           | {-7.12908167688326,0.87648787696783,0.127886153027713}
loglikelihood  | -39.14759930999
std_err        | {2.52104008297868,0.639575886323862,0.0445757462972303}
z_stats        | {-2.82783352990566,1.37042045472615,2.86896269049475}
p_values       | {0.00468641692252239,0.170555690550421,0.00411820373218956}
odd_ratios     | {0.000801455044349486,2.40244718187161,1.13642361694409}
condition_no   | 280069.034217586
num_iterations | 5
</pre></li>
<li>View all parameters used during the training <pre class="example">
\x on
SELECT * FROM test3_output_summary;
</pre> Results: <pre class="result">
-[ RECORD 1 ]------------+--------------------------------------------------
method                   | mlogregr
source_table             | test3
out_table                | test3_output
dependent_varname        | cat
independent_varname      | ARRAY[1, feat1, feat2]
optimizer_params         | max_iter=20, optimizer=irls, precision=0.0001
ref_category             | 0
num_categories           | 3
num_rows_processed       | 57
num_missing_rows_skipped | 0
variance_covariance      | {{4.54052482732554,3.01080140927409,-0.551901021610841,-0.380754019900586,-0.0784151362989211,-0.0510014701718268},{3.01080140927409,6.35564309998514,-0.351902272617974,-0.766730342510818,-0.051877550252329,-0.0954432017695571},{-0.551901021610841,-0.351902272617974,0.34225034424253,0.231740815080827,-0.00117521831508331,-0.00114043921343171},{-0.380754019900586,-0.766730342510818,0.231740815080827,0.409057314366954,-0.000556498286025567,-0.000404735750986327},{-0.0784151362989211,-0.051877550252329,-0.00117521831508331,-0.000556498286025569,0.00186181338639984,0.00121080293928445},{-0.0510014701718268,-0.0954432017695571,-0.00114043921343171,-0.000404735750986325,0.00121080293928446,0.00198699715795504}}
coef                     | {{1.45474045211601,0.0849956182104023,-0.0172383499601956},{-7.12908167688326,0.87648787696783,0.127886153027713}}
</pre></li>
</ol>
<p><a class="anchor" id="background"></a></p><dl class="section user"><dt>Technical Background</dt><dd>Multinomial logistic regression models the outcomes of categorical dependent random variables (denoted \( Y \in \{ 0,1,2 \ldots k \} \)). The model assumes that the conditional mean of the dependent categorical variables is the logistic function of an affine combination of independent variables (usually denoted \( \boldsymbol x \)). That is, <p class="formulaDsp">
\[ E[Y \mid \boldsymbol x] = \sigma(\boldsymbol c^T \boldsymbol x) \]
</p>
 for some unknown vector of coefficients \( \boldsymbol c \) and where \( \sigma(x) = \frac{1}{1 + \exp(-x)} \) is the logistic function. Multinomial logistic regression finds the vector of coefficients \( \boldsymbol c \) that maximizes the likelihood of the observations.</dd></dl>
<p>Let</p><ul>
<li>\( \boldsymbol y \in \{ 0,1 \}^{n \times k} \) denote the vector of observed dependent variables, with \( n \) rows and \( k \) columns, containing the observed values of the dependent variable,</li>
<li>\( X \in \mathbf R^{n \times k} \) denote the design matrix with \( k \) columns and \( n \) rows, containing all observed vectors of independent variables \( \boldsymbol x_i \) as rows.</li>
</ul>
<p>By definition, </p><p class="formulaDsp">
\[ P[Y = y_i | \boldsymbol x_i] = \sigma((-1)^{y_i} \cdot \boldsymbol c^T \boldsymbol x_i) \,. \]
</p>
<p> Maximizing the likelihood \( \prod_{i=1}^n \Pr(Y = y_i \mid \boldsymbol x_i) \) is equivalent to maximizing the log-likelihood \( \sum_{i=1}^n \log \Pr(Y = y_i \mid \boldsymbol x_i) \), which simplifies to </p><p class="formulaDsp">
\[ l(\boldsymbol c) = -\sum_{i=1}^n \log(1 + \exp((-1)^{y_i} \cdot \boldsymbol c^T \boldsymbol x_i)) \,. \]
</p>
<p> The Hessian of this objective is \( H = -X^T A X \) where \( A = \text{diag}(a_1, \dots, a_n) \) is the diagonal matrix with \( a_i = \sigma(\boldsymbol c^T \boldsymbol x) \cdot \sigma(-\boldsymbol c^T \boldsymbol x) \,. \) Since \( H \) is non-positive definite, \( l(\boldsymbol c) \) is convex. There are many techniques for solving convex optimization problems. Currently, logistic regression in MADlib can use:</p><ul>
<li>Iteratively Reweighted Least Squares</li>
</ul>
<p>We estimate the standard error for coefficient \( i \) as </p><p class="formulaDsp">
\[ \mathit{se}(c_i) = \left( (X^T A X)^{-1} \right)_{ii} \,. \]
</p>
<p> The Wald z-statistic is </p><p class="formulaDsp">
\[ z_i = \frac{c_i}{\mathit{se}(c_i)} \,. \]
</p>
<p>The Wald \( p \)-value for coefficient \( i \) gives the probability (under the assumptions inherent in the Wald test) of seeing a value at least as extreme as the one observed, provided that the null hypothesis ( \( c_i = 0 \)) is true. Letting \( F \) denote the cumulative density function of a standard normal distribution, the Wald \( p \)-value for coefficient \( i \) is therefore </p><p class="formulaDsp">
\[ p_i = \Pr(|Z| \geq |z_i|) = 2 \cdot (1 - F( |z_i| )) \]
</p>
<p> where \( Z \) is a standard normally distributed random variable.</p>
<p>The odds ratio for coefficient \( i \) is estimated as \( \exp(c_i) \).</p>
<p>The condition number is computed as \( \kappa(X^T A X) \) during the iteration immediately <em>preceding</em> convergence (i.e., \( A \) is computed using the coefficients of the previous iteration). A large condition number (say, more than 1000) indicates the presence of significant multicollinearity.</p>
<p>The multinomial logistic regression uses a default reference category of zero, and the regression coefficients in the output are in the order described below. For a problem with \( K \) dependent variables \( (1, ..., K) \) and \( J \) categories \( (0, ..., J-1) \), let \( {m_{k,j}} \) denote the coefficient for dependent variable \( k \) and category \( j \). The output is \( {m_{k_1, j_0}, m_{k_1, j_1} \ldots m_{k_1, j_{J-1}}, m_{k_2, j_0}, m_{k_2, j_1}, \ldots m_{k_2, j_{J-1}} \ldots m_{k_K, j_{J-1}}} \). The order is NOT CONSISTENT with the multinomial regression marginal effect calculation with function <em>marginal_mlogregr</em>. This is deliberate because the interfaces of all multinomial regressions (robust, clustered, ...) will be moved to match that used in marginal.</p>
<p><a class="anchor" id="literature"></a></p><dl class="section user"><dt>Literature</dt><dd></dd></dl>
<p>A collection of nice write-ups, with valuable pointers into further literature:</p>
<p>[1] Annette J. Dobson: An Introduction to Generalized Linear Models, Second Edition. Nov 2001</p>
<p>[2] Cosma Shalizi: Statistics 36-350: Data Mining, Lecture Notes, 18 November 2009, <a href="http://www.stat.cmu.edu/~cshalizi/350/lectures/26/lecture-26.pdf">http://www.stat.cmu.edu/~cshalizi/350/lectures/26/lecture-26.pdf</a></p>
<p>[3] Scott A. Czepiel: Maximum Likelihood Estimation of Logistic Regression Models: Theory and Implementation, Retrieved Jul 12 2012, <a href="http://czep.net/stat/mlelr.pdf">http://czep.net/stat/mlelr.pdf</a></p>
<p><a class="anchor" id="related"></a></p><dl class="section user"><dt>Related Topics</dt><dd></dd></dl>
<p>File <a class="el" href="multilogistic_8sql__in.html" title="SQL functions for multinomial logistic regression. ">multilogistic.sql_in</a> documenting the multinomial logistic regression functions</p>
<p><a class="el" href="group__grp__logreg.html">Logistic Regression</a></p>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon Oct 15 2018 11:24:30 for MADlib by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
