<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.4"/>
<title>MADlib: Linear Regression</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script src="../mathjax/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">MADlib
   &#160;<span id="projectnumber">1.1</span> <span style="font-size:10pt; font-style:italic"><a href="../latest/./group__grp__linreg.html"> A newer version is available</a></span>
   </div>
   <div id="projectbrief">User Documentation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.4 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('group__grp__linreg.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Linear Regression<div class="ingroups"><a class="el" href="group__grp__glm.html">Generalized Linear Models</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Collaboration diagram for Linear Regression:</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<center><table><tr><td><div class="center"><iframe scrolling="no" frameborder="0" src="group__grp__linreg.svg" width="339" height="56"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
</td></tr></table></center>
</div>
<div class="toc"><b>Contents</b></p>
<ul>
<li class="level1">
<a href="#about">About</a> </li>
<li class="level1">
<a href="#train">Usage</a> </li>
<li class="level2">
<a href="#train">Training Function</a> </li>
<li class="level2">
<a href="#output">Output Table</a> </li>
<li class="level2">
<a href="#predict">Prediction Function</a> </li>
<li class="level1">
<a href="#examples">Examples</a> </li>
<li class="level1">
<a href="#seealso">See Also</a> </li>
<li class="level1">
<a href="#background">Technical Background</a> </li>
<li class="level1">
<a href="#literature">Literature</a> </li>
</ul>
</div><p><a class="anchor" id="about"></a></p>
<dl class="section user"><dt>About:</dt><dd>Ordinary Least Squares Regression, also called Linear Regression, is a statistical model used to fit linear models.</dd></dl>
<p>It models a linear relationship of a scalar dependent variable \( y \) to one or more explanatory independent variables \( x \) to build a model of coefficients.</p>
<p><a class="anchor" id="train"></a></p>
<dl class="section user"><dt>Training Function</dt><dd><pre class="fragment">linregr_train(source_table, out_table,
              dependent_varname,
              independent_varname,
              input_group_cols := NULL,
              heteroskedasticity_option := NULL)
</pre></dd></dl>
<dl class="arglist">
<dt>source_table </dt>
<dd><p class="startdd">Text value. The name of the table containing the training data.</p>
<p class="enddd"></p>
</dd>
<dt>out_table </dt>
<dd><p class="startdd">Text value. Name of the generated table containing the output model.</p>
<p class="enddd"></p>
</dd>
<dt>dependent_varname </dt>
<dd><p class="startdd">Text value. Expression to evaluate for the dependent variable.</p>
<p class="enddd"></p>
</dd>
<dt>independent_varname </dt>
<dd><p class="startdd">Text value. Expression list to evaluate for the independent variables. An intercept variable is not assumed. It is common to provide an explicit intercept term by including a single constant <code>1</code> term in the independent variable list.</p>
<p class="enddd"></p>
</dd>
<dt>input_group_cols </dt>
<dd><p class="startdd">Text value. An expression list used to group the input dataset into discrete groups, running one regression per group. Similar to the SQL <code>GROUP BY</code> clause. When this value is null, no grouping is used and a single result model is generated. Default value: NULL.</p>
<p class="enddd"></p>
</dd>
<dt>heteroskedasticity_option </dt>
<dd>Boolean value. When True, the heteroskedacity of the model is also calculated and returned with the results. Default value: False. </dd>
</dl>
<p><a class="anchor" id="output"></a></p>
<dl class="section user"><dt>Output Table</dt><dd>The output table produced by the linear regression training function contains the following columns. <dl class="arglist">
<dt>&lt;...&gt; </dt>
<dd><p class="startdd">Any grouping columns provided during training. Present only if the grouping option is used.</p>
<p class="enddd"></p>
</dd>
<dt>coef </dt>
<dd><p class="startdd">Float array. Vector of the coefficients of the regression.</p>
<p class="enddd"></p>
</dd>
<dt>r2 </dt>
<dd><p class="startdd">Float. R-squared coefficient of determination of the model.</p>
<p class="enddd"></p>
</dd>
<dt>std_err </dt>
<dd><p class="startdd">Float array. Vector of the standard error of the coefficients.</p>
<p class="enddd"></p>
</dd>
<dt>t_stats </dt>
<dd><p class="startdd">Float array. Vector of the t-statistics of the coefficients.</p>
<p class="enddd"></p>
</dd>
<dt>p_values </dt>
<dd><p class="startdd">Float array. Vector of the p-values of the coefficients.</p>
<p class="enddd"></p>
</dd>
<dt>condition_no </dt>
<dd><p class="startdd">Float array. The condition number of the \(X^{*}X\) matrix. A high condition number is usually an indication that there may be some numeric instability in the result yielding a less reliable model. A high condition number often results when there is a significant amount of colinearity in the underlying design matrix, in which case other regression techniques, such as elastic net regression, may be more appropriate.</p>
<p class="enddd"></p>
</dd>
<dt>bp_stats </dt>
<dd><p class="startdd">Float. The Breush-Pagan statistic of heteroskedacity. Present only if the heteroskedacity argument was set to True when the model was trained.</p>
<p class="enddd"></p>
</dd>
<dt>bp_p_value </dt>
<dd>Float. The Breush-Pagan calculated p-value. Present only if the heteroskedacity parameter was set to True when the model was trained. </dd>
</dl>
</dd></dl>
<p><a class="anchor" id="predict"></a></p>
<dl class="section user"><dt>Prediction Function</dt><dd><pre class="fragment">linregr_predict(
  coef,
  col_ind
)
</pre> <dl class="arglist">
<dt>coef </dt>
<dd><p class="startdd">Float array. Vector of the coefficients of regression.</p>
<p class="enddd"></p>
</dd>
<dt>col_ind </dt>
<dd><p class="startdd">Float array. An array containing the independent variable column names. </p>
<p class="enddd"><a class="anchor" id="examples"></a></p>
</dd>
</dl>
</dd></dl>
<dl class="section user"><dt>Examples</dt><dd><ol type="1">
<li>Create an input data set. <pre class="fragment">CREATE TABLE houses (id INT, tax INT, bedroom INT, bath FLOAT, price INT,
            size INT, lot INT);
COPY houses FROM STDIN WITH DELIMITER '|';
  1 |  590 |       2 |    1 |  50000 |  770 | 22100
  2 | 1050 |       3 |    2 |  85000 | 1410 | 12000
  3 |   20 |       3 |    1 |  22500 | 1060 |  3500
  4 |  870 |       2 |    2 |  90000 | 1300 | 17500
  5 | 1320 |       3 |    2 | 133000 | 1500 | 30000
  6 | 1350 |       2 |    1 |  90500 |  820 | 25700
  7 | 2790 |       3 |  2.5 | 260000 | 2130 | 25000
  8 |  680 |       2 |    1 | 142500 | 1170 | 22000
  9 | 1840 |       3 |    2 | 160000 | 1500 | 19000
 10 | 3680 |       4 |    2 | 240000 | 2790 | 20000
 11 | 1660 |       3 |    1 |  87000 | 1030 | 17500
 12 | 1620 |       3 |    2 | 118600 | 1250 | 20000
 13 | 3100 |       3 |    2 | 140000 | 1760 | 38000
 14 | 2070 |       2 |    3 | 148000 | 1550 | 14000
 15 |  650 |       3 |  1.5 |  65000 | 1450 | 12000
\.
</pre></li>
<li>Train a regression model. <pre class="fragment">-- A single regression for all the data
SELECT madlib.linregr_train(
    'houses', 'houses_linregr', 'price', 'array[1, tax, bath, size]');

-- 3 output models, one for each value of "bedroom"
SELECT madlib.linregr_train(
    'houses', 'houses_linregr_bedroom', 'price', 'array[1, tax, bath, size]',
    'bedroom');
</pre></li>
<li>Examine the resulting models. <pre class="fragment">-- Set extended display on for easier reading of output
\x on
SELECT * from houses_linregr;
SELECT * FROM houses_linregr_bedroom;

-- Alternatively you can unnest the results for easier reading of output
\x off
SELECT unnest(array['intercept','tax','bath','size']) as attribute,
       unnest(coef) as coefficient,
       unnest(std_err) as standard_error,
       unnest(t_stats) as t_stat,
       unnest(p_values) as pvalue
FROM houses_linregr;
</pre></li>
<li>Use the prediction function to evaluate residuals. <pre class="fragment">SELECT houses.*,
       madlib.linregr_predict(array[1,tax,bath,size], m.coef) as predict,
         price - madlib.linregr_predict(array[1,tax,bath,size], m.coef)
            as residual
FROM houses, houses_linregr m;
</pre></li>
</ol>
</dd></dl>
<p><a class="anchor" id="seealso"></a></p>
<dl class="section see"><dt>See Also</dt><dd>File <a class="el" href="linear_8sql__in.html" title="SQL functions for linear regression. ">linear.sql_in</a>, documenting the SQL training functions </dd>
<dd>
<a class="el" href="linear_8sql__in.html#a71d8295a18e93619b3331cefabe6e79b" title="Compute linear regression coefficients and diagnostic statistics. ">linregr()</a> </dd>
<dd>
<a class="el" href="logistic_8sql__in.html#a32880a39de2e36b6c6be72691a6a4a40" title="Compute logistic-regression coefficients and diagnostic statistics. ">logregr_train()</a> </dd>
<dd>
<a class="el" href="elastic__net_8sql__in.html#a735038a5090c112505c740a90a203e83" title="Interface for elastic net. ">elastic_net_train()</a> </dd>
<dd>
<a class="el" href="group__grp__robust.html">Huber White Variance</a> </dd>
<dd>
<a class="el" href="group__grp__clustered__errors.html">Clustered Variance</a> </dd>
<dd>
<a class="el" href="group__grp__validation.html">Cross Validation</a></dd></dl>
<p><a class="anchor" id="background"></a></p>
<dl class="section user"><dt>Technical Background</dt><dd></dd></dl>
<p>Ordinary least-squares (OLS) linear regression refers to a stochastic model in which the conditional mean of the dependent variable (usually denoted \( Y \)) is an affine function of the vector of independent variables (usually denoted \( \boldsymbol x \)). That is, </p>
<p class="formulaDsp">
\[ E[Y \mid \boldsymbol x] = \boldsymbol c^T \boldsymbol x \]
</p>
<p> for some unknown vector of coefficients \( \boldsymbol c \). The assumption is that the residuals are i.i.d. distributed Gaussians. That is, the (conditional) probability density of \( Y \) is given by </p>
<p class="formulaDsp">
\[ f(y \mid \boldsymbol x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot \exp\left(-\frac{1}{2 \sigma^2} \cdot (y - \boldsymbol x^T \boldsymbol c)^2 \right) \,. \]
</p>
<p> OLS linear regression finds the vector of coefficients \( \boldsymbol c \) that maximizes the likelihood of the observations.</p>
<p>Let</p>
<ul>
<li>\( \boldsymbol y \in \mathbf R^n \) denote the vector of observed dependent variables, with \( n \) rows, containing the observed values of the dependent variable,</li>
<li>\( X \in \mathbf R^{n \times k} \) denote the design matrix with \( k \) columns and \( n \) rows, containing all observed vectors of independent variables. \( \boldsymbol x_i \) as rows,</li>
<li>\( X^T \) denote the transpose of \( X \),</li>
<li>\( X^+ \) denote the pseudo-inverse of \( X \).</li>
</ul>
<p>Maximizing the likelihood is equivalent to maximizing the log-likelihood \( \sum_{i=1}^n \log f(y_i \mid \boldsymbol x_i) \), which simplifies to minimizing the <b>residual sum of squares</b> \( RSS \) (also called sum of squared residuals or sum of squared errors of prediction), </p>
<p class="formulaDsp">
\[ RSS = \sum_{i=1}^n ( y_i - \boldsymbol c^T \boldsymbol x_i )^2 = (\boldsymbol y - X \boldsymbol c)^T (\boldsymbol y - X \boldsymbol c) \,. \]
</p>
<p> The first-order conditions yield that the \( RSS \) is minimized at </p>
<p class="formulaDsp">
\[ \boldsymbol c = (X^T X)^+ X^T \boldsymbol y \,. \]
</p>
<p>Computing the <b>total sum of squares</b> \( TSS \), the <b>explained sum of squares</b> \( ESS \) (also called the regression sum of squares), and the <b>coefficient of determination</b> \( R^2 \) is done according to the following formulas: </p>
<p class="formulaDsp">
\begin{align*} ESS &amp; = \boldsymbol y^T X \boldsymbol c - \frac{ \| y \|_1^2 }{n} \\ TSS &amp; = \sum_{i=1}^n y_i^2 - \frac{ \| y \|_1^2 }{n} \\ R^2 &amp; = \frac{ESS}{TSS} \end{align*}
</p>
<p> Note: The last equality follows from the definition \( R^2 = 1 - \frac{RSS}{TSS} \) and the fact that for linear regression \( TSS = RSS + ESS \). A proof of the latter can be found, e.g., at: <a href="http://en.wikipedia.org/wiki/Sum_of_squares">http://en.wikipedia.org/wiki/Sum_of_squares</a></p>
<p>We estimate the variance \( Var[Y - \boldsymbol c^T \boldsymbol x \mid \boldsymbol x] \) as </p>
<p class="formulaDsp">
\[ \sigma^2 = \frac{RSS}{n - k} \]
</p>
<p> and compute the t-statistic for coefficient \( i \) as </p>
<p class="formulaDsp">
\[ t_i = \frac{c_i}{\sqrt{\sigma^2 \cdot \left( (X^T X)^{-1} \right)_{ii} }} \,. \]
</p>
<p>The \( p \)-value for coefficient \( i \) gives the probability of seeing a value at least as extreme as the one observed, provided that the null hypothesis ( \( c_i = 0 \)) is true. Letting \( F_\nu \) denote the cumulative density function of student-t with \( \nu \) degrees of freedom, the \( p \)-value for coefficient \( i \) is therefore </p>
<p class="formulaDsp">
\[ p_i = \Pr(|T| \geq |t_i|) = 2 \cdot (1 - F_{n - k}( |t_i| )) \]
</p>
<p> where \( T \) is a student-t distributed random variable with mean 0.</p>
<p>The condition number [2] \( \kappa(X) = \|X\|_2\cdot\|X^{-1}\|_2\) is computed as the product of two spectral norms [3]. The spectral norm of a matrix \(X\) is the largest singular value of \(X\) i.e. the square root of the largest eigenvalue of the positive-semidefinite matrix \(X^{*}X\):</p>
<p class="formulaDsp">
\[ \|X\|_2 = \sqrt{\lambda_{\max}\left(X^{*}X\right)}\ , \]
</p>
<p> where \(X^{*}\) is the conjugate transpose of \(X\). The condition number of a linear regression problem is a worst-case measure of how sensitive the result is to small perturbations of the input. A large condition number (say, more than 1000) indicates the presence of significant multicollinearity.</p>
<p><a class="anchor" id="literature"></a></p>
<dl class="section user"><dt>Literature:</dt><dd></dd></dl>
<p>[1] Cosma Shalizi: Statistics 36-350: Data Mining, Lecture Notes, 21 October 2009, <a href="http://www.stat.cmu.edu/~cshalizi/350/lectures/17/lecture-17.pdf">http://www.stat.cmu.edu/~cshalizi/350/lectures/17/lecture-17.pdf</a></p>
<p>[2] Wikipedia: Condition Number, <a href="http://en.wikipedia.org/wiki/Condition_number">http://en.wikipedia.org/wiki/Condition_number</a>.</p>
<p>[3] Wikipedia: Spectral Norm, <a href="http://en.wikipedia.org/wiki/Spectral_norm#Spectral_norm">http://en.wikipedia.org/wiki/Spectral_norm#Spectral_norm</a></p>
<p>[4] Wikipedia: Breuschâ€“Pagan test, <a href="http://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test">http://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test</a></p>
<p>[5] Wikipedia: Heteroscedasticity-consistent standard errors, <a href="http://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors">http://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors</a> </p>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Wed Aug 21 2013 16:09:52 for MADlib by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.4 </li>
  </ul>
</div>
</body>
</html>
